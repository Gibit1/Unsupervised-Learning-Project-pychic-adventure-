{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad4730e-f483-4bf8-a4b4-4f0684e4f923",
   "metadata": {},
   "source": [
    "## AKONA CIKO _Unsupervised Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d89267-360d-44e8-96c3-7a99c0aa51c3",
   "metadata": {},
   "source": [
    "### Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6459763-948a-4382-b857-0326278bbbb1",
   "metadata": {},
   "source": [
    "1. Project Overview\n",
    "3. Dataset details\n",
    "4. Packages & Libraries\n",
    "5. Data collection & loading\n",
    "6. Data Pre-processsing & Processing\n",
    "7. Model training\n",
    "8. Model deployment\n",
    "9. Monitor model\n",
    "10. Project Manager / Contributor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7cc385-3522-47f6-ae6f-e75bee915f1c",
   "metadata": {},
   "source": [
    "#### 1. Project Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ca11a-5a4e-4945-8c5b-1a09795d56b1",
   "metadata": {},
   "source": [
    "Key objectives_\n",
    "\n",
    "1. Build a recommendation system using Collaborative Filtering (CF) and Content-Based Filtering (CBF).\n",
    "3. Accurately predict ratings for unseen anime titles.\n",
    "4. Develop a model that can be deployed in a production environment.\n",
    "5. Implement data pre-processing to clean and prepare the data for training.\n",
    "6. Develop a model that can be deployed in a production environment.\n",
    "7. Monitor the system's performance after deployment and make updates as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d75980e-be8f-4c07-b211-22187e937995",
   "metadata": {},
   "source": [
    "Performing an initial review of my collected data for completeness and relevance involves systematically examining the dataset to ensure it is suitable for my Project & ensure it is the correct dataset.\n",
    "\n",
    "This project focuses on building a collaborative and content-based recommender system for anime titles. The goal is to predict how a user will rate an anime they havenâ€™t yet seen, based on both their historical preferences and the content (such as genre, description, etc.) of the anime itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc2e4c-3d45-40a1-948a-67cc8ffa0de8",
   "metadata": {},
   "source": [
    "#### 2. Dataset details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ab18e-42b9-4e6d-ba26-0096127e7056",
   "metadata": {},
   "source": [
    "For this project, the dataset is titled \"Anime-dataset-2023\". The data consists of user ratings and metadata about anime titles. Here's a breakdown of the data fields:\n",
    "\n",
    "User Ratings:\n",
    "User ID: A unique identifier for each user.\n",
    "Anime ID: A unique identifier for each anime.\n",
    "Rating: The score a user has given to an anime (1-10 scale, or possibly a 0-5 scale).\n",
    "Timestamp: The time at which the rating was given.\n",
    "Anime Metadata:\n",
    "Anime ID: Unique identifier for each anime.\n",
    "Title: Name of the anime.\n",
    "Genres: List of genres the anime falls under (e.g., action, comedy, drama).\n",
    "Description: A short summary of the anime's plot.\n",
    "Year: The year the anime was released.\n",
    "Type: Type of anime (e.g., TV series, movie, OVA).\n",
    "Episodes: Number of episodes in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5eb53-483b-4602-b1e1-55df6724090c",
   "metadata": {},
   "source": [
    "#### 3. Packages & Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb69191-2fa7-4196-80db-3f91f2b7bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Packges & Libraries to Use_\n",
    "\n",
    "I will need a set of libraries for this project, including those for data processing, machine learning, and model evaluation.\n",
    "\n",
    "Required Packages:\n",
    "\n",
    "pandas: For data manipulation and analysis.\n",
    "numpy: For numerical operations.\n",
    "scikit-learn: For machine learning algorithms and metrics.\n",
    "surprise: A Python library for building recommender systems.\n",
    "tensorflow or pytorch: For deep learning models, if needed.\n",
    "matplotlib and seaborn: For data visualization.\n",
    "flask or fastAPI: For model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15e920-41ee-463e-99a1-22a98e8666c5",
   "metadata": {},
   "source": [
    "#### 4. Data collection & loading: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181ac51-e097-4405-a9bf-1acef324f831",
   "metadata": {},
   "source": [
    "Data Sources:\n",
    "\n",
    "Collect data from available anime rating datasets, such as MyAnimeList or Kaggle Anime Datasets.\n",
    "For anime metadata, scrape websites like AniList, Kitsu, or use official APIs from anime databases.\n",
    "Data Loading:\n",
    "\n",
    "Wil pandas to load the dataset from CSV, JSON, or directly from databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b395b0-407e-432a-9de3-c5aba6c90bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (145572391.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    anime_metadata = pd.read_csv('anime_metadata = pd.read_csv'('C:\\\\Users\\\\F8871503\\\\OneDrive - FRG\\\\Documents.csv')\u001b[0m\n\u001b[1;37m                                                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "anime_metadata = pd.read_csv('anime_metadata = pd.read_csv'('C:\\\\Users\\\\F8871503\\\\OneDrive - FRG\\\\Documents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065c8a2-cfd7-48da-b74f-2b8a98f95475",
   "metadata": {},
   "source": [
    "#### 5. Data Pre-processsing & Processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212d738-e78a-4318-8d3b-bc017f14cbb6",
   "metadata": {},
   "source": [
    "1. Handling Missing Data:\n",
    "For user ratings, I willfill missing ratings with mean or median values, or drop them if necessary.\n",
    "For metadata, you may need to fill missing values (e.g., genres, descriptions) with placeholders or use other imputation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681a9fe-497d-4f01-8d6f-41a600da8b54",
   "metadata": {},
   "source": [
    "2. Data Transformation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a121e07-7b02-40e7-a529-ab3c30446131",
   "metadata": {},
   "source": [
    "Text Processing: If using content-based filtering, process anime descriptions by converting them into a numerical format (using TF-IDF or Word2Vec).\n",
    "Genre Encoding: Convert anime genres into a numerical representation using one-hot encoding or label encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa865c4-74fd-45cf-bed5-c42e67717fc7",
   "metadata": {},
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Example encoding for anime genres\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "genre_encoded = encoder.fit_transform(anime_metadata[['genres']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34da317-77de-43e3-a32f-5f50edb59ce6",
   "metadata": {},
   "source": [
    "3. Feature Engineering:\n",
    "Will Create features such as average rating, number of ratings, and anime release yearm? ///////???///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f03741-325e-4df9-95f1-8a7396408e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Model training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4374d-d527-4991-b8c7-afc6f01b32f1",
   "metadata": {},
   "source": [
    "Matrix Factorization: Use methods like SVD (Singular Value Decomposition) or ALS (Alternating Least Squares) to factorize the user-item rating matrix.\n",
    "Example using Surprise Library for SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27bbfab-d50a-46d1-8eed-622643bebabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))  # Assuming ratings are on a scale of 1-10\n",
    "data = Dataset.load_from_df(user_ratings[['user_id', 'anime_id', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7527c8-a585-495b-97ef-fc202b7c5f1c",
   "metadata": {},
   "source": [
    "Content-Based Filtering (CBF): TF-IDF: Convert the anime descriptions to a term frequency-inverse document frequency (TF-IDF) matrix and use cosine similarity to compute recommendations.\n",
    "Example using TF-IDF for content-based filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c37288-f305-48bf-afc5-ea698a6037e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(anime_metadata['description'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad528cc2-61aa-4197-bc58-3d60ca6e5101",
   "metadata": {},
   "source": [
    "Hybrid Model:\n",
    "Combine both CF and CBF for a hybrid recommendation system. Use CF for collaborative recommendations and CBF for content-based suggestions. Blend them based on user preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523d427-c6ca-4609-b9ab-fdea3f34078b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317c279-9c0c-4af2-9336-d64f23dcdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Model deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfaaf75-ab13-43c5-9a67-27df88239a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c7ac5a-dca3-40ee-8e00-fc8b5bbedfe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'â€¢' (U+2022) (2541502328.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    â€¢ Matrix Factorization: Use methods like SVD (Singular Value Decomposition) or ALS (Alternating Least Squares) to factorize the user-item rating matrix.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character 'â€¢' (U+2022)\n"
     ]
    }
   ],
   "source": [
    "Use pickle or joblib to save the trained model for later use.\n",
    "                                              \n",
    "import joblib\n",
    "joblib.dump(model, 'svd_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6ca94-7335-48a4-8f01-6f599c21c188",
   "metadata": {},
   "source": [
    "After training and tuning the model, deploy it to a production environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f3e9f-366b-4a42-83ae-7f17eec2cd3c",
   "metadata": {},
   "source": [
    "1. Model Serialization: Use pickle or joblib to save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19122b-5e96-420b-8f42-7a41200dbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'svd_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd7395-9db8-4494-8203-7cc60fe47f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Collaborative Filtering (CF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c531135-9fd3-4386-9431-9bc0f46d0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Monitor model:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3870e4-731b-4dde-92a4-cc0a73a7952a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732e5df-ce0b-40c0-9903-66e782c887a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Project Manager / Contributor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d66dc1-7a55-465e-8261-06e88118e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project Manager / Contributor: Akona Ciko | Akonaciko1@gmail.com | Gibit1 (GitHub username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b0843-05f6-4f10-83de-cdbd74f9ce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7057d38-ec55-4d98-be8a-55378d0c160f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
