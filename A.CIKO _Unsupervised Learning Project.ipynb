{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad4730e-f483-4bf8-a4b4-4f0684e4f923",
   "metadata": {},
   "source": [
    "## AKONA CIKO _Unsupervised Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d89267-360d-44e8-96c3-7a99c0aa51c3",
   "metadata": {},
   "source": [
    "### Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6459763-948a-4382-b857-0326278bbbb1",
   "metadata": {},
   "source": [
    "1. Project Overview\n",
    "3. Dataset details\n",
    "4. Packages & Libraries\n",
    "5. Data collection & loading\n",
    "6. Data Pre-processsing & Processing\n",
    "7. Model training\n",
    "8. Model deployment\n",
    "9. Monitor model\n",
    "10. Project Manager / Contributor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84d49f-78f3-4020-a0c2-3a9e79b71901",
   "metadata": {},
   "source": [
    "#### Requirements Text.file_file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5868f-92cd-40c1-a7e9-03bce8a0d75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b7cc385-3522-47f6-ae6f-e75bee915f1c",
   "metadata": {},
   "source": [
    "#### 1. Project Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ca11a-5a4e-4945-8c5b-1a09795d56b1",
   "metadata": {},
   "source": [
    "Key objectives_\n",
    "\n",
    "1. Build a recommendation system using Collaborative Filtering (CF) and Content-Based Filtering (CBF).\n",
    "3. Accurately predict ratings for unseen anime titles.\n",
    "4. Develop a model that can be deployed in a production environment.\n",
    "5. Implement data pre-processing to clean and prepare the data for training.\n",
    "6. Develop a model that can be deployed in a production environment.\n",
    "7. Monitor the system's performance after deployment and make updates as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d75980e-be8f-4c07-b211-22187e937995",
   "metadata": {},
   "source": [
    "Performing an initial review of my collected data for completeness and relevance involves systematically examining the dataset to ensure it is suitable for my Project & ensure it is the correct dataset.\n",
    "\n",
    "This project focuses on building a collaborative and content-based recommender system for anime titles. The goal is to predict how a user will rate an anime they havenâ€™t yet seen, based on both their historical preferences and the content (such as genre, description, etc.) of the anime itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc2e4c-3d45-40a1-948a-67cc8ffa0de8",
   "metadata": {},
   "source": [
    "#### 2. Dataset details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ab18e-42b9-4e6d-ba26-0096127e7056",
   "metadata": {},
   "source": [
    "For this project, the dataset is titled \"Anime-dataset-2023\". The data consists of user ratings and metadata about anime titles. Here's a breakdown of the data fields:\n",
    "\n",
    "User Ratings:\n",
    "User ID: A unique identifier for each user.\n",
    "Anime ID: A unique identifier for each anime.\n",
    "Rating: The score a user has given to an anime (1-10 scale, or possibly a 0-5 scale).\n",
    "Timestamp: The time at which the rating was given.\n",
    "Anime Metadata:\n",
    "Anime ID: Unique identifier for each anime.\n",
    "Title: Name of the anime.\n",
    "Genres: List of genres the anime falls under (e.g., action, comedy, drama).\n",
    "Description: A short summary of the anime's plot.\n",
    "Year: The year the anime was released.\n",
    "Type: Type of anime (e.g., TV series, movie, OVA).\n",
    "Episodes: Number of episodes in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5eb53-483b-4602-b1e1-55df6724090c",
   "metadata": {},
   "source": [
    "#### 3. Packages & Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb69191-2fa7-4196-80db-3f91f2b7bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Packges & Libraries to Use_\n",
    "\n",
    "I will need a set of libraries for this project, including those for data processing, machine learning, and model evaluation.\n",
    "\n",
    "Required Packages:\n",
    "pandas: For data manipulation and analysis.\n",
    "numpy: For numerical operations.\n",
    "scikit-learn: For machine learning algorithms and metrics.\n",
    "surprise: A Python library for building recommender systems.\n",
    "tensorflow or pytorch: For deep learning models, if needed.\n",
    "matplotlib and seaborn: For data visualization.\n",
    "flask or fastAPI: For model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15e920-41ee-463e-99a1-22a98e8666c5",
   "metadata": {},
   "source": [
    "#### 4. Data collection & loading: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181ac51-e097-4405-a9bf-1acef324f831",
   "metadata": {},
   "source": [
    "Data Sources:\n",
    "\n",
    "Collect data from available anime rating datasets, such as MyAnimeList or Kaggle Anime Datasets.\n",
    "For anime metadata, scrape websites like AniList, Kitsu, or use official APIs from anime databases.\n",
    "Data Loading:\n",
    "\n",
    "Wil pandas to load the dataset from CSV, JSON, or directly from databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b395b0-407e-432a-9de3-c5aba6c90bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/F8871503/OneDrive-FRG/Documents/Explore_AI Data_Science/Unsupervised Learning.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m anime_metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/F8871503/OneDrive-FRG/Documents/Explore_AI Data_Science/Unsupervised Learning.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\ProgramData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\ProgramData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\ProgramData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\ProgramData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\ProgramData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/F8871503/OneDrive-FRG/Documents/Explore_AI Data_Science/Unsupervised Learning.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "anime_metadata = pd.read_csv(r'C:/Users/F8871503/OneDrive-FRG/Documents/Explore_AI Data_Science/Unsupervised Learning.csv')  # Anime metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c850e80a-f9ca-4987-8298-02390d16b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = r'C:\\Users\\F8871503\\OneDrive - FRG\\Documents\\Explore_AI Data_Science\\Unsupervised Learning.csv'\n",
    "print(os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b503296-ac8d-4aac-8e71-8d3e3658d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Data Pre-processsing & Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104a07c-9f2c-4e0d-b24d-ac7d567f259b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f03741-325e-4df9-95f1-8a7396408e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7ac5a-dca3-40ee-8e00-fc8b5bbedfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317c279-9c0c-4af2-9336-d64f23dcdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Model deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd7395-9db8-4494-8203-7cc60fe47f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c531135-9fd3-4386-9431-9bc0f46d0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Monitor model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3870e4-731b-4dde-92a4-cc0a73a7952a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732e5df-ce0b-40c0-9903-66e782c887a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Project Manager / Contributor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d66dc1-7a55-465e-8261-06e88118e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project Manager / Contributor: Akona Ciko | Akonaciko1@gmail.com | Gibit1 (GitHub username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b0843-05f6-4f10-83de-cdbd74f9ce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7057d38-ec55-4d98-be8a-55378d0c160f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
